{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "# We don't use the whole dataset for efficiency purpose, but feel free to increase these numbers\n",
    "n_train_items = 60032\n",
    "n_test_items = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part X - Secure Training and Evaluation on MNIST\n",
    "\n",
    "When building Machine Learning as a Service solutions (MLaaS), a company might need to request access to data from other partners to train its model. In health or in finance, both the model and the data are extremely critical: the model parameters is a business asset while data is personal data which is tightly regulated.\n",
    "\n",
    "In this context, one possible solution is to encrypt both the model and the data and to train the machine learning model over the encrypted values. This guarantees that the company won't access patients medical records for example and that health facilities won't be able to observe the model to which they contribute. Several encryption schemes exist that allow for computation over encrypted data, among which Secure Multi-Party Computation (SMPC), Homomorphic Encryption (FHE/SHE) and Functional Encryption (FE). We will focus here on Multi-Party Computation (which have been introduced in Tutorial 5) which consists of private additive sharing and relies on the crypto protocols SecureNN and SPDZ.\n",
    "\n",
    "The exact setting of this tutorial is the following: consider that you are the server and you would like to train your model on some data held by $n$ workers. The server secret shares his model and send each share to a worker. The workers also secret share their data and exchange it between them. In the configuration that we will study, there are 2 workers: alice and bob. After exchanging shares, each of them now has one of their own shares, one share of the other worker, and one share of the model. Computation can now start to privately train the model using the appropriate crypto protocols. Once the model is trained, all the shares can be sent back to the server to decrypt it. This is illustrated with the following figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SMPC Illustration](https://github.com/OpenMined/PySyft/raw/11c85a121a1a136e354945686622ab3731246084/examples/tutorials/material/smpc_illustration.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give an example of this process, let's assume alice and bob both hold a part of the MNIST dataset and let's train a model to perform digit classification!\n",
    "\n",
    "Author:\n",
    "- Théo Ryffel - Twitter: [@theoryffel](https://twitter.com/theoryffel) · GitHub: [@LaRiffle](https://github.com/LaRiffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Encrypted Training demo on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class describes all the hyper-parameters for the training. Note that they are all public here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.test_batch_size = 50\n",
    "        self.epochs = epochs\n",
    "        self.lr = 0.001\n",
    "        self.seed = 1\n",
    "        self.log_interval = 1 # Log info at each batch\n",
    "        self.precision_fractional = 3\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "_ = torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are PySyft imports. We connect to two remote workers that be call `alice` and `bob` and request another worker called the `crypto_provider` who gives all the crypto primitives we may need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "import syft as sy  # import the Pysyft library\n",
    "hook = sy.TorchHook(torch)  # hook PyTorch to add extra functionalities like Federated and Encrypted Learning\n",
    "\n",
    "# simulation functions\n",
    "def connect_to_workers(n_workers):\n",
    "    return [\n",
    "        sy.VirtualWorker(hook, id=f\"worker{i+1}\")\n",
    "        for i in range(n_workers)\n",
    "    ]\n",
    "def connect_to_crypto_provider():\n",
    "    return sy.VirtualWorker(hook, id=\"crypto_provider\")\n",
    "\n",
    "workers = connect_to_workers(n_workers=2)\n",
    "crypto_provider = connect_to_crypto_provider()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting access and secret share data\n",
    "\n",
    "Here we're using a utility function which simulates the following behaviour: we assume the MNIST dataset is distributed in parts each of which is held by one of our workers. The workers then split their data in batches and secret share their data between each others. The final object returned is an iterable on these secret shared batches, that we call the **private data loader**. Note that during the process the local worker (so us) never had access to the data.\n",
    "\n",
    "We obtain as usual a training and testing private dataset, and both the inputs and labels are secret shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_private_data_loaders(precision_fractional, workers, crypto_provider):\n",
    "    \n",
    "    def one_hot_of(index_tensor):\n",
    "        \"\"\"\n",
    "        Transform to one hot tensor\n",
    "        \n",
    "        Example:\n",
    "            [0, 3, 9]\n",
    "            =>\n",
    "            [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "             [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "             [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]\n",
    "            \n",
    "        \"\"\"\n",
    "        onehot_tensor = torch.zeros(*index_tensor.shape, 10) # 10 classes for MNIST\n",
    "        onehot_tensor = onehot_tensor.scatter(1, index_tensor.view(-1, 1), 1)\n",
    "        return onehot_tensor\n",
    "        \n",
    "    def secret_share(tensor):\n",
    "        \"\"\"\n",
    "        Transform to fixed precision and secret share a tensor\n",
    "        \"\"\"\n",
    "        return (\n",
    "            tensor\n",
    "            .fix_precision(precision_fractional=precision_fractional)\n",
    "            .share(*workers, crypto_provider=crypto_provider, requires_grad=True)\n",
    "        )\n",
    "    \n",
    "    transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)) #mean and std dev on dataset but how do you know if it's secret shared?\n",
    "    ])\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True, transform=transformation),\n",
    "        batch_size=args.batch_size\n",
    "    )\n",
    "    \n",
    "    private_train_loader = [\n",
    "        (secret_share(data), secret_share(one_hot_of(target)))\n",
    "        for i, (data, target) in enumerate(train_loader)\n",
    "        if i < n_train_items / args.batch_size\n",
    "    ]\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, download=True, transform=transformation),\n",
    "        batch_size=args.test_batch_size\n",
    "    )\n",
    "    \n",
    "    private_test_loader = [\n",
    "        (secret_share(data), secret_share(target.float()))\n",
    "        for i, (data, target) in enumerate(test_loader)\n",
    "        if i < n_test_items / args.test_batch_size\n",
    "    ]\n",
    "    \n",
    "    return private_train_loader, private_test_loader\n",
    "    \n",
    "    \n",
    "private_train_loader, private_test_loader = get_private_data_loaders(\n",
    "    precision_fractional=args.precision_fractional,\n",
    "    workers=workers,\n",
    "    crypto_provider=crypto_provider\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model specification\n",
    "\n",
    "Here is the model that we will use, it's a rather simple one but [it has proved to perform reasonably well on MNIST](https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing functions\n",
    "\n",
    "The training is done almost as usual, the real difference is that we can't use losses like negative log-likelihood (`F.nll_loss` in PyTorch) because it's quite complicated to reproduce these functions with SMPC. Instead, we use a simpler Mean Square Error loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, private_train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(private_train_loader): # <-- now it is a private dataset\n",
    "        start_time = time.time()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        # loss = F.nll_loss(output, target)  <-- not possible here\n",
    "        batch_size = output.shape[0]\n",
    "        loss = ((output - target)**2).sum().refresh()/batch_size\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            loss = loss.get().float_precision()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTime: {:.3f}s'.format(\n",
    "                epoch, batch_idx * args.batch_size, len(private_train_loader) * args.batch_size,\n",
    "                100. * batch_idx / len(private_train_loader), loss.item(), time.time() - start_time))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test function does not change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, private_test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in private_test_loader:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target.view_as(pred)).sum()\n",
    "\n",
    "    correct = correct.get().float_precision()\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct.item(), len(private_test_loader)* args.test_batch_size,\n",
    "        100. * correct.item() / (len(private_test_loader) * args.test_batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's launch the training !\n",
    "\n",
    "A few notes about what's happening here. First, we secret share all the model parameters across our workers. Second, we convert optimizer's hyperparameters to fixed precision. Note that we don't need to secret share them because they are public in our context, but as secret shared values live in finite fields we still need to move them in finite fields using `.fix_precision`, in order to perform consistently operations like the weight update $W \\leftarrow W - \\alpha * \\Delta W$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60032 (0%)]\tLoss: 1.591000\tTime: 19.713s\n",
      "Train Epoch: 1 [64/60032 (0%)]\tLoss: 1.480000\tTime: 19.417s\n",
      "Train Epoch: 1 [128/60032 (0%)]\tLoss: 1.251000\tTime: 17.217s\n",
      "Train Epoch: 1 [192/60032 (0%)]\tLoss: 1.377000\tTime: 17.683s\n",
      "Train Epoch: 1 [256/60032 (0%)]\tLoss: 1.148000\tTime: 18.011s\n",
      "Train Epoch: 1 [320/60032 (1%)]\tLoss: 1.074000\tTime: 16.910s\n",
      "Train Epoch: 1 [384/60032 (1%)]\tLoss: 1.142000\tTime: 18.051s\n",
      "Train Epoch: 1 [448/60032 (1%)]\tLoss: 1.193000\tTime: 16.061s\n",
      "Train Epoch: 1 [512/60032 (1%)]\tLoss: 1.195000\tTime: 16.852s\n",
      "Train Epoch: 1 [576/60032 (1%)]\tLoss: 1.193000\tTime: 16.225s\n",
      "Train Epoch: 1 [640/60032 (1%)]\tLoss: 1.067000\tTime: 16.616s\n",
      "Train Epoch: 1 [704/60032 (1%)]\tLoss: 1.016000\tTime: 23.608s\n",
      "Train Epoch: 1 [768/60032 (1%)]\tLoss: 0.975000\tTime: 16.591s\n",
      "Train Epoch: 1 [832/60032 (1%)]\tLoss: 1.106000\tTime: 16.995s\n",
      "Train Epoch: 1 [896/60032 (1%)]\tLoss: 0.996000\tTime: 16.584s\n",
      "Train Epoch: 1 [960/60032 (2%)]\tLoss: 1.075000\tTime: 16.949s\n",
      "Train Epoch: 1 [1024/60032 (2%)]\tLoss: 1.024000\tTime: 16.635s\n",
      "Train Epoch: 1 [1088/60032 (2%)]\tLoss: 1.035000\tTime: 19.538s\n",
      "Train Epoch: 1 [1152/60032 (2%)]\tLoss: 0.952000\tTime: 26.371s\n",
      "Train Epoch: 1 [1216/60032 (2%)]\tLoss: 1.012000\tTime: 22.533s\n",
      "Train Epoch: 1 [1280/60032 (2%)]\tLoss: 1.017000\tTime: 17.192s\n",
      "Train Epoch: 1 [1344/60032 (2%)]\tLoss: 0.943000\tTime: 16.956s\n",
      "Train Epoch: 1 [1408/60032 (2%)]\tLoss: 0.997000\tTime: 16.621s\n",
      "Train Epoch: 1 [1472/60032 (2%)]\tLoss: 0.972000\tTime: 16.863s\n",
      "Train Epoch: 1 [1536/60032 (3%)]\tLoss: 1.002000\tTime: 16.780s\n",
      "Train Epoch: 1 [1600/60032 (3%)]\tLoss: 0.959000\tTime: 15.990s\n",
      "Train Epoch: 1 [1664/60032 (3%)]\tLoss: 0.870000\tTime: 19.248s\n",
      "Train Epoch: 1 [1728/60032 (3%)]\tLoss: 0.929000\tTime: 18.404s\n",
      "Train Epoch: 1 [1792/60032 (3%)]\tLoss: 0.885000\tTime: 20.228s\n",
      "Train Epoch: 1 [1856/60032 (3%)]\tLoss: 0.901000\tTime: 17.858s\n",
      "Train Epoch: 1 [1920/60032 (3%)]\tLoss: 0.903000\tTime: 17.343s\n",
      "Train Epoch: 1 [1984/60032 (3%)]\tLoss: 0.869000\tTime: 17.823s\n",
      "Train Epoch: 1 [2048/60032 (3%)]\tLoss: 0.870000\tTime: 17.445s\n",
      "Train Epoch: 1 [2112/60032 (4%)]\tLoss: 0.915000\tTime: 17.088s\n",
      "Train Epoch: 1 [2176/60032 (4%)]\tLoss: 0.895000\tTime: 18.572s\n",
      "Train Epoch: 1 [2240/60032 (4%)]\tLoss: 0.924000\tTime: 18.976s\n",
      "Train Epoch: 1 [2304/60032 (4%)]\tLoss: 0.904000\tTime: 21.378s\n",
      "Train Epoch: 1 [2368/60032 (4%)]\tLoss: 0.879000\tTime: 19.989s\n",
      "Train Epoch: 1 [2432/60032 (4%)]\tLoss: 0.896000\tTime: 17.477s\n",
      "Train Epoch: 1 [2496/60032 (4%)]\tLoss: 0.949000\tTime: 17.700s\n",
      "Train Epoch: 1 [2560/60032 (4%)]\tLoss: 0.848000\tTime: 17.745s\n",
      "Train Epoch: 1 [2624/60032 (4%)]\tLoss: 0.847000\tTime: 16.955s\n",
      "Train Epoch: 1 [2688/60032 (4%)]\tLoss: 0.833000\tTime: 17.373s\n",
      "Train Epoch: 1 [2752/60032 (5%)]\tLoss: 0.831000\tTime: 16.440s\n",
      "Train Epoch: 1 [2816/60032 (5%)]\tLoss: 0.807000\tTime: 16.719s\n",
      "Train Epoch: 1 [2880/60032 (5%)]\tLoss: 0.811000\tTime: 16.734s\n",
      "Train Epoch: 1 [2944/60032 (5%)]\tLoss: 0.798000\tTime: 17.364s\n",
      "Train Epoch: 1 [3008/60032 (5%)]\tLoss: 0.859000\tTime: 17.078s\n",
      "Train Epoch: 1 [3072/60032 (5%)]\tLoss: 0.765000\tTime: 17.260s\n",
      "Train Epoch: 1 [3136/60032 (5%)]\tLoss: 0.830000\tTime: 16.976s\n",
      "Train Epoch: 1 [3200/60032 (5%)]\tLoss: 0.793000\tTime: 19.515s\n",
      "Train Epoch: 1 [3264/60032 (5%)]\tLoss: 0.776000\tTime: 19.330s\n",
      "Train Epoch: 1 [3328/60032 (6%)]\tLoss: 0.858000\tTime: 17.859s\n",
      "Train Epoch: 1 [3392/60032 (6%)]\tLoss: 0.825000\tTime: 17.802s\n",
      "Train Epoch: 1 [3456/60032 (6%)]\tLoss: 0.867000\tTime: 20.252s\n",
      "Train Epoch: 1 [3520/60032 (6%)]\tLoss: 0.860000\tTime: 17.132s\n",
      "Train Epoch: 1 [3584/60032 (6%)]\tLoss: 0.791000\tTime: 17.953s\n",
      "Train Epoch: 1 [3648/60032 (6%)]\tLoss: 0.828000\tTime: 18.635s\n",
      "Train Epoch: 1 [3712/60032 (6%)]\tLoss: 0.809000\tTime: 18.413s\n",
      "Train Epoch: 1 [3776/60032 (6%)]\tLoss: 0.758000\tTime: 18.280s\n",
      "Train Epoch: 1 [3840/60032 (6%)]\tLoss: 0.732000\tTime: 19.188s\n",
      "Train Epoch: 1 [3904/60032 (7%)]\tLoss: 0.802000\tTime: 22.922s\n",
      "Train Epoch: 1 [3968/60032 (7%)]\tLoss: 0.796000\tTime: 18.137s\n",
      "Train Epoch: 1 [4032/60032 (7%)]\tLoss: 0.743000\tTime: 16.635s\n",
      "Train Epoch: 1 [4096/60032 (7%)]\tLoss: 0.730000\tTime: 23.717s\n",
      "Train Epoch: 1 [4160/60032 (7%)]\tLoss: 0.736000\tTime: 19.898s\n",
      "Train Epoch: 1 [4224/60032 (7%)]\tLoss: 0.757000\tTime: 24.231s\n",
      "Train Epoch: 1 [4288/60032 (7%)]\tLoss: 0.803000\tTime: 19.850s\n",
      "Train Epoch: 1 [4352/60032 (7%)]\tLoss: 0.775000\tTime: 20.397s\n",
      "Train Epoch: 1 [4416/60032 (7%)]\tLoss: 0.798000\tTime: 19.666s\n",
      "Train Epoch: 1 [4480/60032 (7%)]\tLoss: 0.685000\tTime: 17.900s\n",
      "Train Epoch: 1 [4544/60032 (8%)]\tLoss: 0.685000\tTime: 17.174s\n",
      "Train Epoch: 1 [4608/60032 (8%)]\tLoss: 0.748000\tTime: 16.970s\n",
      "Train Epoch: 1 [4672/60032 (8%)]\tLoss: 0.775000\tTime: 18.202s\n",
      "Train Epoch: 1 [4736/60032 (8%)]\tLoss: 0.767000\tTime: 23.055s\n",
      "Train Epoch: 1 [4800/60032 (8%)]\tLoss: 0.814000\tTime: 19.451s\n",
      "Train Epoch: 1 [4864/60032 (8%)]\tLoss: 0.721000\tTime: 17.878s\n",
      "Train Epoch: 1 [4928/60032 (8%)]\tLoss: 0.689000\tTime: 17.500s\n",
      "Train Epoch: 1 [4992/60032 (8%)]\tLoss: 0.690000\tTime: 17.603s\n",
      "Train Epoch: 1 [5056/60032 (8%)]\tLoss: 0.720000\tTime: 19.046s\n",
      "Train Epoch: 1 [5120/60032 (9%)]\tLoss: 0.745000\tTime: 21.285s\n",
      "Train Epoch: 1 [5184/60032 (9%)]\tLoss: 0.684000\tTime: 17.654s\n",
      "Train Epoch: 1 [5248/60032 (9%)]\tLoss: 0.729000\tTime: 17.462s\n",
      "Train Epoch: 1 [5312/60032 (9%)]\tLoss: 0.716000\tTime: 17.822s\n",
      "Train Epoch: 1 [5376/60032 (9%)]\tLoss: 0.661000\tTime: 18.669s\n",
      "Train Epoch: 1 [5440/60032 (9%)]\tLoss: 0.626000\tTime: 18.459s\n",
      "Train Epoch: 1 [5504/60032 (9%)]\tLoss: 0.677000\tTime: 18.985s\n",
      "Train Epoch: 1 [5568/60032 (9%)]\tLoss: 0.693000\tTime: 17.821s\n",
      "Train Epoch: 1 [5632/60032 (9%)]\tLoss: 0.692000\tTime: 18.431s\n",
      "Train Epoch: 1 [5696/60032 (9%)]\tLoss: 0.730000\tTime: 18.190s\n",
      "Train Epoch: 1 [5760/60032 (10%)]\tLoss: 0.702000\tTime: 18.737s\n",
      "Train Epoch: 1 [5824/60032 (10%)]\tLoss: 0.674000\tTime: 18.706s\n",
      "Train Epoch: 1 [5888/60032 (10%)]\tLoss: 0.675000\tTime: 25.502s\n",
      "Train Epoch: 1 [5952/60032 (10%)]\tLoss: 0.620000\tTime: 22.539s\n",
      "Train Epoch: 1 [6016/60032 (10%)]\tLoss: 0.605000\tTime: 22.610s\n",
      "Train Epoch: 1 [6080/60032 (10%)]\tLoss: 0.592000\tTime: 18.461s\n",
      "Train Epoch: 1 [6144/60032 (10%)]\tLoss: 0.679000\tTime: 21.552s\n",
      "Train Epoch: 1 [6208/60032 (10%)]\tLoss: 0.651000\tTime: 19.659s\n",
      "Train Epoch: 1 [6272/60032 (10%)]\tLoss: 0.660000\tTime: 21.432s\n",
      "Train Epoch: 1 [6336/60032 (11%)]\tLoss: 0.627000\tTime: 18.946s\n",
      "Train Epoch: 1 [6400/60032 (11%)]\tLoss: 0.706000\tTime: 18.904s\n",
      "Train Epoch: 1 [6464/60032 (11%)]\tLoss: 0.684000\tTime: 19.367s\n",
      "Train Epoch: 1 [6528/60032 (11%)]\tLoss: 0.563000\tTime: 19.869s\n",
      "Train Epoch: 1 [6592/60032 (11%)]\tLoss: 0.547000\tTime: 17.667s\n",
      "Train Epoch: 1 [6656/60032 (11%)]\tLoss: 0.618000\tTime: 17.940s\n",
      "Train Epoch: 1 [6720/60032 (11%)]\tLoss: 0.666000\tTime: 18.053s\n",
      "Train Epoch: 1 [6784/60032 (11%)]\tLoss: 0.740000\tTime: 17.637s\n",
      "Train Epoch: 1 [6848/60032 (11%)]\tLoss: 0.677000\tTime: 17.829s\n",
      "Train Epoch: 1 [6912/60032 (12%)]\tLoss: 0.633000\tTime: 18.340s\n",
      "Train Epoch: 1 [6976/60032 (12%)]\tLoss: 0.672000\tTime: 18.060s\n",
      "Train Epoch: 1 [7040/60032 (12%)]\tLoss: 0.709000\tTime: 17.720s\n",
      "Train Epoch: 1 [7104/60032 (12%)]\tLoss: 0.644000\tTime: 18.224s\n",
      "Train Epoch: 1 [7168/60032 (12%)]\tLoss: 0.689000\tTime: 18.142s\n",
      "Train Epoch: 1 [7232/60032 (12%)]\tLoss: 0.783000\tTime: 17.727s\n",
      "Train Epoch: 1 [7296/60032 (12%)]\tLoss: 0.734000\tTime: 18.316s\n",
      "Train Epoch: 1 [7360/60032 (12%)]\tLoss: 0.653000\tTime: 17.791s\n",
      "Train Epoch: 1 [7424/60032 (12%)]\tLoss: 0.738000\tTime: 19.122s\n",
      "Train Epoch: 1 [7488/60032 (12%)]\tLoss: 0.674000\tTime: 18.368s\n",
      "Train Epoch: 1 [7552/60032 (13%)]\tLoss: 0.610000\tTime: 17.649s\n",
      "Train Epoch: 1 [7616/60032 (13%)]\tLoss: 0.704000\tTime: 18.194s\n",
      "Train Epoch: 1 [7680/60032 (13%)]\tLoss: 0.674000\tTime: 18.471s\n",
      "Train Epoch: 1 [7744/60032 (13%)]\tLoss: 0.674000\tTime: 18.115s\n",
      "Train Epoch: 1 [7808/60032 (13%)]\tLoss: 0.660000\tTime: 18.048s\n",
      "Train Epoch: 1 [7872/60032 (13%)]\tLoss: 0.672000\tTime: 17.700s\n",
      "Train Epoch: 1 [7936/60032 (13%)]\tLoss: 0.615000\tTime: 19.000s\n",
      "Train Epoch: 1 [8000/60032 (13%)]\tLoss: 0.686000\tTime: 18.429s\n",
      "Train Epoch: 1 [8064/60032 (13%)]\tLoss: 0.641000\tTime: 18.113s\n",
      "Train Epoch: 1 [8128/60032 (14%)]\tLoss: 0.615000\tTime: 18.433s\n",
      "Train Epoch: 1 [8192/60032 (14%)]\tLoss: 0.696000\tTime: 17.657s\n",
      "Train Epoch: 1 [8256/60032 (14%)]\tLoss: 0.665000\tTime: 18.582s\n",
      "Train Epoch: 1 [8320/60032 (14%)]\tLoss: 0.614000\tTime: 19.190s\n",
      "Train Epoch: 1 [8384/60032 (14%)]\tLoss: 0.663000\tTime: 18.582s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [8448/60032 (14%)]\tLoss: 0.617000\tTime: 22.833s\n",
      "Train Epoch: 1 [8512/60032 (14%)]\tLoss: 0.554000\tTime: 25.748s\n",
      "Train Epoch: 1 [8576/60032 (14%)]\tLoss: 0.596000\tTime: 19.574s\n",
      "Train Epoch: 1 [8640/60032 (14%)]\tLoss: 0.711000\tTime: 22.589s\n",
      "Train Epoch: 1 [8704/60032 (14%)]\tLoss: 0.710000\tTime: 24.045s\n",
      "Train Epoch: 1 [8768/60032 (15%)]\tLoss: 0.653000\tTime: 24.684s\n",
      "Train Epoch: 1 [8832/60032 (15%)]\tLoss: 0.794000\tTime: 24.314s\n",
      "Train Epoch: 1 [8896/60032 (15%)]\tLoss: 0.597000\tTime: 19.799s\n",
      "Train Epoch: 1 [8960/60032 (15%)]\tLoss: 0.567000\tTime: 20.128s\n",
      "Train Epoch: 1 [9024/60032 (15%)]\tLoss: 0.566000\tTime: 19.261s\n",
      "Train Epoch: 1 [9088/60032 (15%)]\tLoss: 0.661000\tTime: 20.037s\n",
      "Train Epoch: 1 [9152/60032 (15%)]\tLoss: 0.580000\tTime: 19.384s\n",
      "Train Epoch: 1 [9216/60032 (15%)]\tLoss: 0.632000\tTime: 19.982s\n",
      "Train Epoch: 1 [9280/60032 (15%)]\tLoss: 0.637000\tTime: 20.266s\n",
      "Train Epoch: 1 [9344/60032 (16%)]\tLoss: 0.590000\tTime: 20.159s\n",
      "Train Epoch: 1 [9408/60032 (16%)]\tLoss: 0.617000\tTime: 19.347s\n",
      "Train Epoch: 1 [9472/60032 (16%)]\tLoss: 0.602000\tTime: 20.416s\n",
      "Train Epoch: 1 [9536/60032 (16%)]\tLoss: 0.689000\tTime: 22.083s\n",
      "Train Epoch: 1 [9600/60032 (16%)]\tLoss: 0.594000\tTime: 20.829s\n",
      "Train Epoch: 1 [9664/60032 (16%)]\tLoss: 0.549000\tTime: 19.316s\n",
      "Train Epoch: 1 [9728/60032 (16%)]\tLoss: 0.627000\tTime: 20.410s\n",
      "Train Epoch: 1 [9792/60032 (16%)]\tLoss: 0.561000\tTime: 22.950s\n",
      "Train Epoch: 1 [9856/60032 (16%)]\tLoss: 0.550000\tTime: 19.319s\n",
      "Train Epoch: 1 [9920/60032 (17%)]\tLoss: 0.577000\tTime: 18.986s\n",
      "Train Epoch: 1 [9984/60032 (17%)]\tLoss: 0.594000\tTime: 20.109s\n",
      "Train Epoch: 1 [10048/60032 (17%)]\tLoss: 0.648000\tTime: 19.492s\n",
      "Train Epoch: 1 [10112/60032 (17%)]\tLoss: 0.567000\tTime: 18.762s\n",
      "Train Epoch: 1 [10176/60032 (17%)]\tLoss: 0.647000\tTime: 19.822s\n",
      "Train Epoch: 1 [10240/60032 (17%)]\tLoss: 0.628000\tTime: 22.119s\n",
      "Train Epoch: 1 [10304/60032 (17%)]\tLoss: 0.512000\tTime: 22.898s\n",
      "Train Epoch: 1 [10368/60032 (17%)]\tLoss: 0.543000\tTime: 21.278s\n",
      "Train Epoch: 1 [10432/60032 (17%)]\tLoss: 0.590000\tTime: 24.468s\n",
      "Train Epoch: 1 [10496/60032 (17%)]\tLoss: 0.549000\tTime: 19.129s\n",
      "Train Epoch: 1 [10560/60032 (18%)]\tLoss: 0.588000\tTime: 19.287s\n",
      "Train Epoch: 1 [10624/60032 (18%)]\tLoss: 0.598000\tTime: 19.909s\n",
      "Train Epoch: 1 [10688/60032 (18%)]\tLoss: 0.621000\tTime: 21.913s\n",
      "Train Epoch: 1 [10752/60032 (18%)]\tLoss: 0.581000\tTime: 19.949s\n",
      "Train Epoch: 1 [10816/60032 (18%)]\tLoss: 0.519000\tTime: 20.382s\n",
      "Train Epoch: 1 [10880/60032 (18%)]\tLoss: 0.545000\tTime: 19.162s\n",
      "Train Epoch: 1 [10944/60032 (18%)]\tLoss: 0.518000\tTime: 19.632s\n",
      "Train Epoch: 1 [11008/60032 (18%)]\tLoss: 0.507000\tTime: 19.769s\n",
      "Train Epoch: 1 [11072/60032 (18%)]\tLoss: 0.606000\tTime: 21.140s\n",
      "Train Epoch: 1 [11136/60032 (19%)]\tLoss: 0.574000\tTime: 20.754s\n",
      "Train Epoch: 1 [11200/60032 (19%)]\tLoss: 0.585000\tTime: 19.696s\n",
      "Train Epoch: 1 [11264/60032 (19%)]\tLoss: 0.490000\tTime: 19.125s\n",
      "Train Epoch: 1 [11328/60032 (19%)]\tLoss: 0.533000\tTime: 22.205s\n",
      "Train Epoch: 1 [11392/60032 (19%)]\tLoss: 0.497000\tTime: 28.454s\n",
      "Train Epoch: 1 [11456/60032 (19%)]\tLoss: 0.560000\tTime: 23.505s\n",
      "Train Epoch: 1 [11520/60032 (19%)]\tLoss: 0.579000\tTime: 21.942s\n",
      "Train Epoch: 1 [11584/60032 (19%)]\tLoss: 0.684000\tTime: 19.058s\n",
      "Train Epoch: 1 [11648/60032 (19%)]\tLoss: 0.618000\tTime: 19.651s\n",
      "Train Epoch: 1 [11712/60032 (20%)]\tLoss: 0.646000\tTime: 19.215s\n",
      "Train Epoch: 1 [11776/60032 (20%)]\tLoss: 0.614000\tTime: 18.923s\n",
      "Train Epoch: 1 [11840/60032 (20%)]\tLoss: 0.585000\tTime: 19.913s\n",
      "Train Epoch: 1 [11904/60032 (20%)]\tLoss: 0.597000\tTime: 20.333s\n",
      "Train Epoch: 1 [11968/60032 (20%)]\tLoss: 0.535000\tTime: 19.148s\n",
      "Train Epoch: 1 [12032/60032 (20%)]\tLoss: 0.581000\tTime: 19.476s\n",
      "Train Epoch: 1 [12096/60032 (20%)]\tLoss: 0.515000\tTime: 19.192s\n",
      "Train Epoch: 1 [12160/60032 (20%)]\tLoss: 0.579000\tTime: 19.073s\n",
      "Train Epoch: 1 [12224/60032 (20%)]\tLoss: 0.604000\tTime: 19.620s\n",
      "Train Epoch: 1 [12288/60032 (20%)]\tLoss: 0.607000\tTime: 18.966s\n",
      "Train Epoch: 1 [12352/60032 (21%)]\tLoss: 0.558000\tTime: 19.353s\n",
      "Train Epoch: 1 [12416/60032 (21%)]\tLoss: 0.585000\tTime: 19.434s\n",
      "Train Epoch: 1 [12480/60032 (21%)]\tLoss: 0.588000\tTime: 18.870s\n",
      "Train Epoch: 1 [12544/60032 (21%)]\tLoss: 0.641000\tTime: 19.534s\n",
      "Train Epoch: 1 [12608/60032 (21%)]\tLoss: 0.675000\tTime: 19.631s\n",
      "Train Epoch: 1 [12672/60032 (21%)]\tLoss: 0.599000\tTime: 19.469s\n",
      "Train Epoch: 1 [12736/60032 (21%)]\tLoss: 0.601000\tTime: 19.701s\n",
      "Train Epoch: 1 [12800/60032 (21%)]\tLoss: 0.591000\tTime: 19.892s\n",
      "Train Epoch: 1 [12864/60032 (21%)]\tLoss: 0.587000\tTime: 19.314s\n",
      "Train Epoch: 1 [12928/60032 (22%)]\tLoss: 0.649000\tTime: 19.949s\n",
      "Train Epoch: 1 [12992/60032 (22%)]\tLoss: 0.627000\tTime: 21.505s\n",
      "Train Epoch: 1 [13056/60032 (22%)]\tLoss: 0.620000\tTime: 26.285s\n",
      "Train Epoch: 1 [13120/60032 (22%)]\tLoss: 0.588000\tTime: 20.049s\n",
      "Train Epoch: 1 [13184/60032 (22%)]\tLoss: 0.518000\tTime: 26.728s\n",
      "Train Epoch: 1 [13248/60032 (22%)]\tLoss: 0.592000\tTime: 21.679s\n",
      "Train Epoch: 1 [13312/60032 (22%)]\tLoss: 0.651000\tTime: 23.390s\n",
      "Train Epoch: 1 [13376/60032 (22%)]\tLoss: 0.506000\tTime: 22.176s\n",
      "Train Epoch: 1 [13440/60032 (22%)]\tLoss: 0.505000\tTime: 23.257s\n",
      "Train Epoch: 1 [13504/60032 (22%)]\tLoss: 0.506000\tTime: 23.179s\n",
      "Train Epoch: 1 [13568/60032 (23%)]\tLoss: 0.478000\tTime: 23.947s\n",
      "Train Epoch: 1 [13632/60032 (23%)]\tLoss: 0.602000\tTime: 22.415s\n",
      "Train Epoch: 1 [13696/60032 (23%)]\tLoss: 0.570000\tTime: 26.386s\n",
      "Train Epoch: 1 [13760/60032 (23%)]\tLoss: 0.531000\tTime: 22.845s\n",
      "Train Epoch: 1 [13824/60032 (23%)]\tLoss: 0.577000\tTime: 20.487s\n",
      "Train Epoch: 1 [13888/60032 (23%)]\tLoss: 0.621000\tTime: 21.619s\n",
      "Train Epoch: 1 [13952/60032 (23%)]\tLoss: 0.672000\tTime: 24.719s\n",
      "Train Epoch: 1 [14016/60032 (23%)]\tLoss: 0.540000\tTime: 21.359s\n",
      "Train Epoch: 1 [14080/60032 (23%)]\tLoss: 0.589000\tTime: 21.163s\n",
      "Train Epoch: 1 [14144/60032 (24%)]\tLoss: 0.600000\tTime: 21.107s\n",
      "Train Epoch: 1 [14208/60032 (24%)]\tLoss: 0.541000\tTime: 23.192s\n",
      "Train Epoch: 1 [14272/60032 (24%)]\tLoss: 0.647000\tTime: 24.606s\n",
      "Train Epoch: 1 [14336/60032 (24%)]\tLoss: 0.636000\tTime: 25.369s\n",
      "Train Epoch: 1 [14400/60032 (24%)]\tLoss: 0.566000\tTime: 20.963s\n",
      "Train Epoch: 1 [14464/60032 (24%)]\tLoss: 0.598000\tTime: 20.970s\n",
      "Train Epoch: 1 [14528/60032 (24%)]\tLoss: 0.568000\tTime: 21.957s\n",
      "Train Epoch: 1 [14592/60032 (24%)]\tLoss: 0.657000\tTime: 23.322s\n",
      "Train Epoch: 1 [14656/60032 (24%)]\tLoss: 0.708000\tTime: 21.387s\n",
      "Train Epoch: 1 [14720/60032 (25%)]\tLoss: 0.619000\tTime: 21.106s\n",
      "Train Epoch: 1 [14784/60032 (25%)]\tLoss: 0.649000\tTime: 23.088s\n",
      "Train Epoch: 1 [14848/60032 (25%)]\tLoss: 0.567000\tTime: 23.040s\n",
      "Train Epoch: 1 [14912/60032 (25%)]\tLoss: 0.521000\tTime: 22.179s\n",
      "Train Epoch: 1 [14976/60032 (25%)]\tLoss: 0.521000\tTime: 24.355s\n",
      "Train Epoch: 1 [15040/60032 (25%)]\tLoss: 0.476000\tTime: 23.475s\n",
      "Train Epoch: 1 [15104/60032 (25%)]\tLoss: 0.626000\tTime: 24.689s\n",
      "Train Epoch: 1 [15168/60032 (25%)]\tLoss: 0.528000\tTime: 24.716s\n",
      "Train Epoch: 1 [15232/60032 (25%)]\tLoss: 0.567000\tTime: 23.894s\n",
      "Train Epoch: 1 [15296/60032 (25%)]\tLoss: 0.497000\tTime: 26.297s\n",
      "Train Epoch: 1 [15360/60032 (26%)]\tLoss: 0.579000\tTime: 24.786s\n",
      "Train Epoch: 1 [15424/60032 (26%)]\tLoss: 0.508000\tTime: 26.324s\n",
      "Train Epoch: 1 [15488/60032 (26%)]\tLoss: 0.508000\tTime: 25.859s\n",
      "Train Epoch: 1 [15552/60032 (26%)]\tLoss: 0.486000\tTime: 24.304s\n",
      "Train Epoch: 1 [15616/60032 (26%)]\tLoss: 0.520000\tTime: 25.556s\n",
      "Train Epoch: 1 [15680/60032 (26%)]\tLoss: 0.629000\tTime: 21.943s\n",
      "Train Epoch: 1 [15744/60032 (26%)]\tLoss: 0.602000\tTime: 23.540s\n",
      "Train Epoch: 1 [15808/60032 (26%)]\tLoss: 0.644000\tTime: 25.027s\n",
      "Train Epoch: 1 [15872/60032 (26%)]\tLoss: 0.534000\tTime: 26.231s\n",
      "Train Epoch: 1 [15936/60032 (27%)]\tLoss: 0.583000\tTime: 24.845s\n",
      "Train Epoch: 1 [16000/60032 (27%)]\tLoss: 0.658000\tTime: 22.314s\n",
      "Train Epoch: 1 [16064/60032 (27%)]\tLoss: 0.526000\tTime: 23.285s\n",
      "Train Epoch: 1 [16128/60032 (27%)]\tLoss: 0.508000\tTime: 26.161s\n",
      "Train Epoch: 1 [16192/60032 (27%)]\tLoss: 0.499000\tTime: 26.204s\n",
      "Train Epoch: 1 [16256/60032 (27%)]\tLoss: 0.526000\tTime: 25.204s\n",
      "Train Epoch: 1 [16320/60032 (27%)]\tLoss: 0.535000\tTime: 24.701s\n",
      "Train Epoch: 1 [16384/60032 (27%)]\tLoss: 0.487000\tTime: 26.084s\n",
      "Train Epoch: 1 [16448/60032 (27%)]\tLoss: 0.500000\tTime: 26.372s\n",
      "Train Epoch: 1 [16512/60032 (28%)]\tLoss: 0.514000\tTime: 25.828s\n",
      "Train Epoch: 1 [16576/60032 (28%)]\tLoss: 0.479000\tTime: 24.985s\n",
      "Train Epoch: 1 [16640/60032 (28%)]\tLoss: 0.540000\tTime: 24.873s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [16704/60032 (28%)]\tLoss: 0.570000\tTime: 24.444s\n",
      "Train Epoch: 1 [16768/60032 (28%)]\tLoss: 0.635000\tTime: 24.536s\n",
      "Train Epoch: 1 [16832/60032 (28%)]\tLoss: 0.595000\tTime: 24.665s\n",
      "Train Epoch: 1 [16896/60032 (28%)]\tLoss: 0.563000\tTime: 24.690s\n",
      "Train Epoch: 1 [16960/60032 (28%)]\tLoss: 0.575000\tTime: 25.739s\n",
      "Train Epoch: 1 [17024/60032 (28%)]\tLoss: 0.547000\tTime: 24.176s\n",
      "Train Epoch: 1 [17088/60032 (28%)]\tLoss: 0.594000\tTime: 25.234s\n",
      "Train Epoch: 1 [17152/60032 (29%)]\tLoss: 0.617000\tTime: 29.819s\n",
      "Train Epoch: 1 [17216/60032 (29%)]\tLoss: 0.533000\tTime: 25.418s\n",
      "Train Epoch: 1 [17280/60032 (29%)]\tLoss: 0.457000\tTime: 24.750s\n",
      "Train Epoch: 1 [17344/60032 (29%)]\tLoss: 0.564000\tTime: 24.985s\n",
      "Train Epoch: 1 [17408/60032 (29%)]\tLoss: 0.485000\tTime: 24.844s\n",
      "Train Epoch: 1 [17472/60032 (29%)]\tLoss: 0.629000\tTime: 24.398s\n",
      "Train Epoch: 1 [17536/60032 (29%)]\tLoss: 0.669000\tTime: 24.477s\n",
      "Train Epoch: 1 [17600/60032 (29%)]\tLoss: 0.558000\tTime: 23.896s\n",
      "Train Epoch: 1 [17664/60032 (29%)]\tLoss: 0.616000\tTime: 27.927s\n",
      "Train Epoch: 1 [17728/60032 (30%)]\tLoss: 0.584000\tTime: 28.330s\n",
      "Train Epoch: 1 [17792/60032 (30%)]\tLoss: 0.596000\tTime: 30.459s\n",
      "Train Epoch: 1 [17856/60032 (30%)]\tLoss: 0.566000\tTime: 31.911s\n",
      "Train Epoch: 1 [17920/60032 (30%)]\tLoss: 0.468000\tTime: 30.459s\n",
      "Train Epoch: 1 [17984/60032 (30%)]\tLoss: 0.537000\tTime: 28.565s\n",
      "Train Epoch: 1 [18048/60032 (30%)]\tLoss: 0.536000\tTime: 27.715s\n",
      "Train Epoch: 1 [18112/60032 (30%)]\tLoss: 0.474000\tTime: 27.108s\n",
      "Train Epoch: 1 [18176/60032 (30%)]\tLoss: 0.476000\tTime: 25.630s\n",
      "Train Epoch: 1 [18240/60032 (30%)]\tLoss: 0.489000\tTime: 26.637s\n",
      "Train Epoch: 1 [18304/60032 (30%)]\tLoss: 0.483000\tTime: 30.903s\n",
      "Train Epoch: 1 [18368/60032 (31%)]\tLoss: 0.581000\tTime: 26.388s\n",
      "Train Epoch: 1 [18432/60032 (31%)]\tLoss: 0.530000\tTime: 30.196s\n",
      "Train Epoch: 1 [18496/60032 (31%)]\tLoss: 0.470000\tTime: 28.113s\n",
      "Train Epoch: 1 [18560/60032 (31%)]\tLoss: 0.519000\tTime: 25.573s\n",
      "Train Epoch: 1 [18624/60032 (31%)]\tLoss: 0.551000\tTime: 29.034s\n",
      "Train Epoch: 1 [18688/60032 (31%)]\tLoss: 0.561000\tTime: 26.031s\n",
      "Train Epoch: 1 [18752/60032 (31%)]\tLoss: 0.433000\tTime: 28.659s\n",
      "Train Epoch: 1 [18816/60032 (31%)]\tLoss: 0.500000\tTime: 25.999s\n",
      "Train Epoch: 1 [18880/60032 (31%)]\tLoss: 0.442000\tTime: 26.561s\n",
      "Train Epoch: 1 [18944/60032 (32%)]\tLoss: 0.501000\tTime: 25.071s\n",
      "Train Epoch: 1 [19008/60032 (32%)]\tLoss: 0.530000\tTime: 21.006s\n",
      "Train Epoch: 1 [19072/60032 (32%)]\tLoss: 0.558000\tTime: 21.194s\n",
      "Train Epoch: 1 [19136/60032 (32%)]\tLoss: 0.562000\tTime: 22.292s\n",
      "Train Epoch: 1 [19200/60032 (32%)]\tLoss: 0.482000\tTime: 23.590s\n",
      "Train Epoch: 1 [19264/60032 (32%)]\tLoss: 0.490000\tTime: 21.220s\n",
      "Train Epoch: 1 [19328/60032 (32%)]\tLoss: 0.483000\tTime: 20.771s\n",
      "Train Epoch: 1 [19392/60032 (32%)]\tLoss: 0.490000\tTime: 21.216s\n",
      "Train Epoch: 1 [19456/60032 (32%)]\tLoss: 0.513000\tTime: 21.622s\n",
      "Train Epoch: 1 [19520/60032 (33%)]\tLoss: 0.515000\tTime: 21.854s\n",
      "Train Epoch: 1 [19584/60032 (33%)]\tLoss: 0.461000\tTime: 21.234s\n",
      "Train Epoch: 1 [19648/60032 (33%)]\tLoss: 0.474000\tTime: 21.769s\n",
      "Train Epoch: 1 [19712/60032 (33%)]\tLoss: 0.418000\tTime: 22.076s\n",
      "Train Epoch: 1 [19776/60032 (33%)]\tLoss: 0.456000\tTime: 21.388s\n",
      "Train Epoch: 1 [19840/60032 (33%)]\tLoss: 0.464000\tTime: 22.656s\n",
      "Train Epoch: 1 [19904/60032 (33%)]\tLoss: 0.616000\tTime: 21.153s\n",
      "Train Epoch: 1 [19968/60032 (33%)]\tLoss: 0.604000\tTime: 23.498s\n",
      "Train Epoch: 1 [20032/60032 (33%)]\tLoss: 0.564000\tTime: 22.100s\n",
      "Train Epoch: 1 [20096/60032 (33%)]\tLoss: 0.512000\tTime: 25.815s\n",
      "Train Epoch: 1 [20160/60032 (34%)]\tLoss: 0.604000\tTime: 21.811s\n",
      "Train Epoch: 1 [20224/60032 (34%)]\tLoss: 0.500000\tTime: 22.719s\n",
      "Train Epoch: 1 [20288/60032 (34%)]\tLoss: 0.506000\tTime: 20.798s\n",
      "Train Epoch: 1 [20352/60032 (34%)]\tLoss: 0.453000\tTime: 21.838s\n",
      "Train Epoch: 1 [20416/60032 (34%)]\tLoss: 0.466000\tTime: 21.464s\n",
      "Train Epoch: 1 [20480/60032 (34%)]\tLoss: 0.448000\tTime: 21.982s\n",
      "Train Epoch: 1 [20544/60032 (34%)]\tLoss: 0.522000\tTime: 21.378s\n",
      "Train Epoch: 1 [20608/60032 (34%)]\tLoss: 0.458000\tTime: 21.547s\n",
      "Train Epoch: 1 [20672/60032 (34%)]\tLoss: 0.519000\tTime: 21.463s\n",
      "Train Epoch: 1 [20736/60032 (35%)]\tLoss: 0.504000\tTime: 21.426s\n",
      "Train Epoch: 1 [20800/60032 (35%)]\tLoss: 0.544000\tTime: 22.197s\n",
      "Train Epoch: 1 [20864/60032 (35%)]\tLoss: 0.547000\tTime: 22.410s\n",
      "Train Epoch: 1 [20928/60032 (35%)]\tLoss: 0.555000\tTime: 21.519s\n",
      "Train Epoch: 1 [20992/60032 (35%)]\tLoss: 0.524000\tTime: 22.120s\n",
      "Train Epoch: 1 [21056/60032 (35%)]\tLoss: 0.425000\tTime: 21.910s\n",
      "Train Epoch: 1 [21120/60032 (35%)]\tLoss: 0.459000\tTime: 22.792s\n",
      "Train Epoch: 1 [21184/60032 (35%)]\tLoss: 0.475000\tTime: 21.626s\n",
      "Train Epoch: 1 [21248/60032 (35%)]\tLoss: 0.493000\tTime: 20.798s\n",
      "Train Epoch: 1 [21312/60032 (36%)]\tLoss: 0.539000\tTime: 21.643s\n",
      "Train Epoch: 1 [21376/60032 (36%)]\tLoss: 0.608000\tTime: 23.441s\n",
      "Train Epoch: 1 [21440/60032 (36%)]\tLoss: 0.488000\tTime: 22.458s\n",
      "Train Epoch: 1 [21504/60032 (36%)]\tLoss: 0.489000\tTime: 21.831s\n",
      "Train Epoch: 1 [21568/60032 (36%)]\tLoss: 0.516000\tTime: 21.420s\n",
      "Train Epoch: 1 [21632/60032 (36%)]\tLoss: 0.482000\tTime: 21.188s\n",
      "Train Epoch: 1 [21696/60032 (36%)]\tLoss: 0.472000\tTime: 21.570s\n",
      "Train Epoch: 1 [21760/60032 (36%)]\tLoss: 0.443000\tTime: 22.331s\n",
      "Train Epoch: 1 [21824/60032 (36%)]\tLoss: 0.432000\tTime: 23.450s\n",
      "Train Epoch: 1 [21888/60032 (36%)]\tLoss: 0.400000\tTime: 21.777s\n",
      "Train Epoch: 1 [21952/60032 (37%)]\tLoss: 0.420000\tTime: 21.536s\n",
      "Train Epoch: 1 [22016/60032 (37%)]\tLoss: 0.551000\tTime: 21.709s\n",
      "Train Epoch: 1 [22080/60032 (37%)]\tLoss: 0.610000\tTime: 21.546s\n",
      "Train Epoch: 1 [22144/60032 (37%)]\tLoss: 0.618000\tTime: 21.405s\n",
      "Train Epoch: 1 [22208/60032 (37%)]\tLoss: 0.528000\tTime: 24.172s\n",
      "Train Epoch: 1 [22272/60032 (37%)]\tLoss: 0.535000\tTime: 21.480s\n",
      "Train Epoch: 1 [22336/60032 (37%)]\tLoss: 0.457000\tTime: 21.517s\n",
      "Train Epoch: 1 [22400/60032 (37%)]\tLoss: 0.507000\tTime: 23.295s\n",
      "Train Epoch: 1 [22464/60032 (37%)]\tLoss: 0.671000\tTime: 22.381s\n",
      "Train Epoch: 1 [22528/60032 (38%)]\tLoss: 0.625000\tTime: 22.137s\n",
      "Train Epoch: 1 [22592/60032 (38%)]\tLoss: 0.529000\tTime: 21.964s\n",
      "Train Epoch: 1 [22656/60032 (38%)]\tLoss: 0.465000\tTime: 21.282s\n",
      "Train Epoch: 1 [22720/60032 (38%)]\tLoss: 0.522000\tTime: 23.976s\n",
      "Train Epoch: 1 [22784/60032 (38%)]\tLoss: 0.499000\tTime: 23.144s\n",
      "Train Epoch: 1 [22848/60032 (38%)]\tLoss: 0.444000\tTime: 27.522s\n",
      "Train Epoch: 1 [22912/60032 (38%)]\tLoss: 0.416000\tTime: 23.581s\n",
      "Train Epoch: 1 [22976/60032 (38%)]\tLoss: 0.473000\tTime: 21.946s\n",
      "Train Epoch: 1 [23040/60032 (38%)]\tLoss: 0.511000\tTime: 24.038s\n",
      "Train Epoch: 1 [23104/60032 (38%)]\tLoss: 0.492000\tTime: 29.114s\n",
      "Train Epoch: 1 [23168/60032 (39%)]\tLoss: 0.495000\tTime: 31.156s\n",
      "Train Epoch: 1 [23232/60032 (39%)]\tLoss: 0.459000\tTime: 34.996s\n",
      "Train Epoch: 1 [23296/60032 (39%)]\tLoss: 0.461000\tTime: 22.270s\n",
      "Train Epoch: 1 [23360/60032 (39%)]\tLoss: 0.504000\tTime: 22.129s\n",
      "Train Epoch: 1 [23424/60032 (39%)]\tLoss: 0.527000\tTime: 22.361s\n",
      "Train Epoch: 1 [23488/60032 (39%)]\tLoss: 0.420000\tTime: 21.581s\n",
      "Train Epoch: 1 [23552/60032 (39%)]\tLoss: 0.450000\tTime: 22.385s\n",
      "Train Epoch: 1 [23616/60032 (39%)]\tLoss: 0.542000\tTime: 22.733s\n",
      "Train Epoch: 1 [23680/60032 (39%)]\tLoss: 0.565000\tTime: 22.919s\n",
      "Train Epoch: 1 [23744/60032 (40%)]\tLoss: 0.493000\tTime: 21.957s\n",
      "Train Epoch: 1 [23808/60032 (40%)]\tLoss: 0.531000\tTime: 22.763s\n",
      "Train Epoch: 1 [23872/60032 (40%)]\tLoss: 0.505000\tTime: 22.414s\n",
      "Train Epoch: 1 [23936/60032 (40%)]\tLoss: 0.479000\tTime: 22.671s\n",
      "Train Epoch: 1 [24000/60032 (40%)]\tLoss: 0.516000\tTime: 22.564s\n",
      "Train Epoch: 1 [24064/60032 (40%)]\tLoss: 0.432000\tTime: 22.754s\n",
      "Train Epoch: 1 [24128/60032 (40%)]\tLoss: 0.405000\tTime: 22.536s\n",
      "Train Epoch: 1 [24192/60032 (40%)]\tLoss: 0.535000\tTime: 21.958s\n",
      "Train Epoch: 1 [24256/60032 (40%)]\tLoss: 0.531000\tTime: 22.086s\n",
      "Train Epoch: 1 [24320/60032 (41%)]\tLoss: 0.447000\tTime: 29.363s\n",
      "Train Epoch: 1 [24384/60032 (41%)]\tLoss: 0.455000\tTime: 26.345s\n",
      "Train Epoch: 1 [24448/60032 (41%)]\tLoss: 0.495000\tTime: 22.903s\n",
      "Train Epoch: 1 [24512/60032 (41%)]\tLoss: 0.496000\tTime: 22.193s\n",
      "Train Epoch: 1 [24576/60032 (41%)]\tLoss: 0.529000\tTime: 21.814s\n",
      "Train Epoch: 1 [24640/60032 (41%)]\tLoss: 0.487000\tTime: 22.060s\n",
      "Train Epoch: 1 [24704/60032 (41%)]\tLoss: 0.537000\tTime: 22.798s\n",
      "Train Epoch: 1 [24768/60032 (41%)]\tLoss: 0.513000\tTime: 22.107s\n",
      "Train Epoch: 1 [24832/60032 (41%)]\tLoss: 0.442000\tTime: 22.947s\n",
      "Train Epoch: 1 [24896/60032 (41%)]\tLoss: 0.540000\tTime: 22.043s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [24960/60032 (42%)]\tLoss: 0.487000\tTime: 22.515s\n",
      "Train Epoch: 1 [25024/60032 (42%)]\tLoss: 0.398000\tTime: 26.853s\n",
      "Train Epoch: 1 [25088/60032 (42%)]\tLoss: 0.466000\tTime: 24.606s\n",
      "Train Epoch: 1 [25152/60032 (42%)]\tLoss: 0.475000\tTime: 22.632s\n",
      "Train Epoch: 1 [25216/60032 (42%)]\tLoss: 0.435000\tTime: 23.915s\n",
      "Train Epoch: 1 [25280/60032 (42%)]\tLoss: 0.556000\tTime: 23.143s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method ObjectPointer.__del__ of [PointerTensor | me:82219469804 -> worker1:77050876030]>\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\generic\\pointers\\object_pointer.py\", line 344, in __del__\n",
      "    self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\workers\\base.py\", line 279, in send_msg\n",
      "    bin_message = sy.serde.serialize(message, worker=self)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\serde.py\", line 43, in serialize\n",
      "    return strategy(obj, worker, simplified, force_full_simplification)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\msgpack\\serde.py\", line 329, in serialize\n",
      "    return _serialize_msgpack_binary(simple_objects)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\msgpack\\serde.py\", line 283, in _serialize_msgpack_binary\n",
      "    binary = msgpack_lib.dumps(simple_objects)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\msgpack\\__init__.py\", line 35, in packb\n",
      "    return Packer(**kwargs).pack(o)\n",
      "  File \"msgpack\\_packer.pyx\", line 114, in msgpack._cmsgpack.Packer.__cinit__\n",
      "MemoryError: Unable to allocate internal buffer.\n",
      "Exception ignored in: <bound method ObjectPointer.__del__ of [PointerTensor | me:49856972992 -> worker2:87335849537]>\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\generic\\pointers\\object_pointer.py\", line 344, in __del__\n",
      "    self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\workers\\base.py\", line 279, in send_msg\n",
      "    bin_message = sy.serde.serialize(message, worker=self)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\serde.py\", line 43, in serialize\n",
      "    return strategy(obj, worker, simplified, force_full_simplification)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\msgpack\\serde.py\", line 329, in serialize\n",
      "    return _serialize_msgpack_binary(simple_objects)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\msgpack\\serde.py\", line 283, in _serialize_msgpack_binary\n",
      "    binary = msgpack_lib.dumps(simple_objects)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\msgpack\\__init__.py\", line 35, in packb\n",
      "    return Packer(**kwargs).pack(o)\n",
      "  File \"msgpack\\_packer.pyx\", line 114, in msgpack._cmsgpack.Packer.__cinit__\n",
      "MemoryError: Unable to allocate internal buffer.\n",
      "Exception ignored in: <bound method ObjectPointer.__del__ of [PointerTensor | me:2181098994 -> worker1:86964245987]>\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\generic\\pointers\\object_pointer.py\", line 344, in __del__\n",
      "    self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\workers\\base.py\", line 279, in send_msg\n",
      "    bin_message = sy.serde.serialize(message, worker=self)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\serde.py\", line 43, in serialize\n",
      "    return strategy(obj, worker, simplified, force_full_simplification)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\msgpack\\serde.py\", line 329, in serialize\n",
      "    return _serialize_msgpack_binary(simple_objects)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\msgpack\\serde.py\", line 283, in _serialize_msgpack_binary\n",
      "    binary = msgpack_lib.dumps(simple_objects)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\msgpack\\__init__.py\", line 35, in packb\n",
      "    return Packer(**kwargs).pack(o)\n",
      "  File \"msgpack\\_packer.pyx\", line 114, in msgpack._cmsgpack.Packer.__cinit__\n",
      "MemoryError: Unable to allocate internal buffer.\n",
      "Exception ignored in: <bound method ObjectPointer.__del__ of [PointerTensor | me:5129833076 -> worker2:58675528948]>\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\generic\\pointers\\object_pointer.py\", line 344, in __del__\n",
      "    self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\workers\\base.py\", line 279, in send_msg\n",
      "    bin_message = sy.serde.serialize(message, worker=self)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\serde.py\", line 43, in serialize\n",
      "    return strategy(obj, worker, simplified, force_full_simplification)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\msgpack\\serde.py\", line 329, in serialize\n",
      "    return _serialize_msgpack_binary(simple_objects)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\msgpack\\serde.py\", line 283, in _serialize_msgpack_binary\n",
      "    binary = msgpack_lib.dumps(simple_objects)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\msgpack\\__init__.py\", line 35, in packb\n",
      "    return Packer(**kwargs).pack(o)\n",
      "  File \"msgpack\\_packer.pyx\", line 114, in msgpack._cmsgpack.Packer.__cinit__\n",
      "MemoryError: Unable to allocate internal buffer.\n",
      "Exception ignored in: <bound method ObjectPointer.__del__ of [PointerTensor | me:28050101526 -> worker1:24901224965]>\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\generic\\pointers\\object_pointer.py\", line 344, in __del__\n",
      "    self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\workers\\base.py\", line 279, in send_msg\n",
      "    bin_message = sy.serde.serialize(message, worker=self)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\serde.py\", line 43, in serialize\n",
      "    return strategy(obj, worker, simplified, force_full_simplification)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\msgpack\\serde.py\", line 329, in serialize\n",
      "    return _serialize_msgpack_binary(simple_objects)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\msgpack\\serde.py\", line 283, in _serialize_msgpack_binary\n",
      "    binary = msgpack_lib.dumps(simple_objects)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\msgpack\\__init__.py\", line 35, in packb\n",
      "    return Packer(**kwargs).pack(o)\n",
      "  File \"msgpack\\_packer.pyx\", line 114, in msgpack._cmsgpack.Packer.__cinit__\n",
      "MemoryError: Unable to allocate internal buffer.\n",
      "Exception ignored in: <bound method ObjectPointer.__del__ of [PointerTensor | me:18636982869 -> worker2:92285065667]>\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\generic\\pointers\\object_pointer.py\", line 344, in __del__\n",
      "    self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\workers\\base.py\", line 279, in send_msg\n",
      "    bin_message = sy.serde.serialize(message, worker=self)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\serde.py\", line 43, in serialize\n",
      "    return strategy(obj, worker, simplified, force_full_simplification)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\msgpack\\serde.py\", line 329, in serialize\n",
      "    return _serialize_msgpack_binary(simple_objects)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\msgpack\\serde.py\", line 283, in _serialize_msgpack_binary\n",
      "    binary = msgpack_lib.dumps(simple_objects)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\msgpack\\__init__.py\", line 35, in packb\n",
      "    return Packer(**kwargs).pack(o)\n",
      "  File \"msgpack\\_packer.pyx\", line 114, in msgpack._cmsgpack.Packer.__cinit__\n",
      "MemoryError: Unable to allocate internal buffer.\n",
      "Exception ignored in: <bound method ObjectPointer.__del__ of [PointerTensor | me:64098359398 -> worker1:12582667601]>\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\generic\\pointers\\object_pointer.py\", line 344, in __del__\n",
      "    self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\workers\\base.py\", line 279, in send_msg\n",
      "    bin_message = sy.serde.serialize(message, worker=self)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\serde.py\", line 43, in serialize\n",
      "    return strategy(obj, worker, simplified, force_full_simplification)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\msgpack\\serde.py\", line 329, in serialize\n",
      "    return _serialize_msgpack_binary(simple_objects)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\serde\\msgpack\\serde.py\", line 283, in _serialize_msgpack_binary\n",
      "    binary = msgpack_lib.dumps(simple_objects)\n",
      "  File \"F:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\msgpack\\__init__.py\", line 35, in packb\n",
      "    return Packer(**kwargs).pack(o)\n",
      "  File \"msgpack\\_packer.pyx\", line 114, in msgpack._cmsgpack.Packer.__cinit__\n",
      "MemoryError: Unable to allocate internal buffer.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 15872000 bytes. Buy new RAM!\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e79443039c9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprivate_train_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprivate_test_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-45f62af47e8d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args, model, private_train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\generic\\frameworks\\hook\\trace.py\u001b[0m in \u001b[0;36mtrace_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[0msyft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\generic\\frameworks\\hook\\hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m                 \u001b[1;31m# Send the new command to the appropriate class and get the response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m                 \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m                 \u001b[1;31m# For inplace methods, just directly return self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\autograd.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, grad)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;31m# And chain structure than self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mbackwards_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\autograd.py\u001b[0m in \u001b[0;36mbackwards_grad\u001b[1;34m(grad_fn, in_grad)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mback_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnext_grad_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_grad\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_functions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mback_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mbackwards_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_grad_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\autograd.py\u001b[0m in \u001b[0;36mbackwards_grad\u001b[1;34m(grad_fn, in_grad)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mback_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnext_grad_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_grad\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_functions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mback_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mbackwards_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_grad_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\autograd.py\u001b[0m in \u001b[0;36mbackwards_grad\u001b[1;34m(grad_fn, in_grad)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mback_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnext_grad_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_grad\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_functions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mback_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mbackwards_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_grad_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\autograd.py\u001b[0m in \u001b[0;36mbackwards_grad\u001b[1;34m(grad_fn, in_grad)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mback_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnext_grad_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_grad\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_functions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mback_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mbackwards_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_grad_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\autograd.py\u001b[0m in \u001b[0;36mbackwards_grad\u001b[1;34m(grad_fn, in_grad)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mback_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnext_grad_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_grad\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_functions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mback_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mbackwards_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_grad_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\autograd.py\u001b[0m in \u001b[0;36mbackwards_grad\u001b[1;34m(grad_fn, in_grad)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mback_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnext_grad_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_grad\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_functions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mback_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mbackwards_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_grad_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\autograd.py\u001b[0m in \u001b[0;36mbackwards_grad\u001b[1;34m(grad_fn, in_grad)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;34m\"to see if it's missing.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         )\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mback_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnext_grad_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_grad\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_functions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mback_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mbackwards_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_grad_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\gradients_core.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, grad)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\gradients.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, grad)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mzero\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mself_\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[0mgt_zero\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mself_\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mzero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgt_zero\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\generic\\frameworks\\overload.py\u001b[0m in \u001b[0;36m_hook_method_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m# Send it to the appropriate class and get the response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_self\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;31m# Put back SyftTensor on the tensors found in the response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\autograd.py\u001b[0m in \u001b[0;36m__gt__\u001b[1;34m(self, _self, other)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0moverloaded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__gt__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_self\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_self\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__gt__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0moverloaded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\generic\\frameworks\\overload.py\u001b[0m in \u001b[0;36m_hook_method_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m# Send it to the appropriate class and get the response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_self\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;31m# Put back SyftTensor on the tensors found in the response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\precision.py\u001b[0m in \u001b[0;36m__gt__\u001b[1;34m(self, _self, other)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0moverloaded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__gt__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_self\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_self\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__gt__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision_fractional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\additive_shared.py\u001b[0m in \u001b[0;36m__gt__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__gt__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    835\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\additive_shared.py\u001b[0m in \u001b[0;36mgt\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    829\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mother\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__gt__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\additive_shared.py\u001b[0m in \u001b[0;36mpositive\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    825\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpositive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m         \u001b[1;31m# self >= 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 827\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msecurenn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_deriv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\mpc\\securenn.py\u001b[0m in \u001b[0;36mrelu_deriv\u001b[1;34m(a_sh)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[1;31m# 3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m     \u001b[0malpha_sh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_sh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0malpha_sh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfield\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\mpc\\securenn.py\u001b[0m in \u001b[0;36mmsb\u001b[1;34m(a_sh)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;31m# 4)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m     \u001b[0mbeta_prime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprivate_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_bit_sh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;31m# 5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\mpc\\securenn.py\u001b[0m in \u001b[0;36mprivate_compare\u001b[1;34m(x_bit_sh, r, beta)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;31m# (I would like to do permuted_mask = mask[..., perm])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_bit_sh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m     \u001b[0mpermuted_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;31m# Send it to another worker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;31m# We do this because we can't allow the local worker to get and see permuted_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\additive_shared.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtensor_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiPointerTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multipointer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_public\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\generic\\frameworks\\overload.py\u001b[0m in \u001b[0;36m_hook_method_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m# Send it to the appropriate class and get the response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_self\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;31m# Put back SyftTensor on the tensors found in the response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\frameworks\\torch\\tensors\\interpreters\\additive_shared.py\u001b[0m in \u001b[0;36m_getitem_multipointer\u001b[1;34m(self, self_shares, indices_shares)\u001b[0m\n\u001b[0;32m    289\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Index type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"not supported\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m             \u001b[0mselected_share\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshare\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m             \u001b[0mselected_shares\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mworker\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselected_share\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\generic\\frameworks\\hook\\hook.py\u001b[0m in \u001b[0;36moverloaded_pointer_method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m             \u001b[1;31m# For inplace methods, just directly return self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\workers\\base.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, recipient, message, return_ids)\u001b[0m\n\u001b[0;32m    516\u001b[0m             ret_val = self.send_msg(\n\u001b[0;32m    517\u001b[0m                 \u001b[0mOperationMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd_owner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m                 \u001b[0mlocation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m             )\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mResponseSignatureError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\workers\\base.py\u001b[0m in \u001b[0;36msend_msg\u001b[1;34m(self, message, location)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m         \u001b[0mbin_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbin_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;31m# Step 3: deserialize the response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\workers\\virtual.py\u001b[0m in \u001b[0;36m_send_msg\u001b[1;34m(self, message, location)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage_pending_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recv_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\workers\\virtual.py\u001b[0m in \u001b[0;36m_recv_msg\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\workers\\base.py\u001b[0m in \u001b[0;36mrecv_msg\u001b[1;34m(self, bin_message)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[1;31m# Step 1: route message to appropriate function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_message_router\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;31m# Step 2: Serialize the message to simple python objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\workers\\base.py\u001b[0m in \u001b[0;36mexecute_command\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m                     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommand_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[1;31m# TODO Andrew thinks this is gross, please fix. Instead need to properly deserialize strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\generic\\frameworks\\hook\\trace.py\u001b[0m in \u001b[0;36mtrace_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[0msyft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\generic\\frameworks\\hook\\hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    436\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                     \u001b[1;31m# we can make some errors more descriptive with this method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mroute_method_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# means that there is a wrapper to remove\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tfe\\lib\\site-packages\\syft\\generic\\frameworks\\hook\\hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m                     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 15872000 bytes. Buy new RAM!\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model = model.fix_precision().share(*workers, crypto_provider=crypto_provider, requires_grad=True)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "optimizer = optimizer.fix_precision() \n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, private_train_loader, optimizer, epoch)\n",
    "    test(args, model, private_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you are! You just get 75% of accuracy using a tiny fraction of the MNIST dataset, using 100% encrypted training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Discussion\n",
    "\n",
    "Let's have a closer look to the power of encrypted training by analyzing what we just did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Computation time\n",
    "\n",
    "First thing is obviously the running time! As you have surely noticed, it is far slower than plain text training. In particular, a iteration over 1 batch of 64 items takes 3.2s while only 13ms in pure PyTorch. Whereas this might seem like a blocker, just recall that here everything happened remotely and in the encrypted world: no single data item has been disclosed. More specifically, the time to process one item is 50ms which is not that bad. The real question is to analyze when encrypted training is needed and when only encrypted prediction is sufficient. 50ms to perform a prediction is completely acceptable in a production-ready scenario for example!\n",
    "\n",
    "One main bottleneck is the use of costly activation functions: relu activation with SMPC are very costly because it uses private comparison and the SecureNN protocol. As an illustration, if we replace relu with a quadratic activation as it is done in several papers on encrypted computation like CryptoNets, we drop from 3.2s to 1.2s.\n",
    "\n",
    "As a general rule, the key idea to take away is to encrypt only what's necessary, and this tutorial shows you how simple it can be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Backpropagation with SMPC\n",
    "\n",
    "You might wonder how we perform backpropagation and gradient updates although we're working with integers in finite fields. To do so, we have developed a new syft tensor called AutogradTensor. This tutorial used it intensively although you might have not seen it! Let's check this by printing a model's weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "(Wrapper)>AutogradTensor>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
       "\t-> [PointerTensor | me:75794498061 -> worker1:82412848383]\n",
       "\t-> [PointerTensor | me:46385483913 -> worker2:11286612429]\n",
       "\t*crypto provider: crypto_provider*"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc3.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a data item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>AutogradTensor>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
       "\t-> [PointerTensor | me:32162462403 -> worker1:43976326703]\n",
       "\t-> [PointerTensor | me:6529537735 -> worker2:65226254314]\n",
       "\t*crypto provider: crypto_provider*"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch, input_data = 0, 0\n",
    "private_train_loader[first_batch][input_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you observe, the AutogradTensor is there! It lives between the torch wrapper and the FixedPrecisionTensor which indicate that the values are now in finite fields. The goal of this AutogradTensor is to store the computation graph when operations are made on encrypted values. This is useful because when calling backward for the backpropagation, this AutogradTensor overrides all the backward functions that are not compatible with encrypted computation and indicates how to compute these gradients. For example, regarding multiplication which is done using the Beaver triples trick, we don't want to differentiate the trick all the more that differentiating a multiplication should be very easy: $\\partial_b (a \\cdot b) = a \\cdot \\partial b$. Here is how we describe how to compute these gradients for example:\n",
    "\n",
    "```python\n",
    "class MulBackward(GradFunc):\n",
    "    def __init__(self, self_, other):\n",
    "        super().__init__(self, self_, other)\n",
    "        self.self_ = self_\n",
    "        self.other = other\n",
    "\n",
    "    def gradient(self, grad):\n",
    "        grad_self_ = grad * self.other\n",
    "        grad_other = grad * self.self_ if type(self.self_) == type(self.other) else None\n",
    "        return (grad_self_, grad_other)\n",
    "```\n",
    "\n",
    "You can have a look at `tensors/interpreters/gradients.py` if you're curious to see how we implemented more gradients.\n",
    "\n",
    "In terms of computation graph, it means that a copy of the graph remains local and that the server which coordinates the forward pass also provide instructions on how to do the backward pass. This is a completely valid hypothesis in our setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Security guarantees\n",
    "\n",
    "\n",
    "Last, let's give a few hints about the security we're achieving here: adversaries that we are considering here are **honest but curious**: this means that an adversary can't learn anything about the data by running this protocol, but a malicious adversary could still deviate from the protocol and for example try to corrupt the shares to sabotage the computation. Security against malicious adversaries in such SMPC computations including private comparison is still an open problem.\n",
    "\n",
    "In addition, even if Secure Multi-Party Computation ensures that training data wasn't accessed, many threats from the plain text world are still present here. For example, as you can make request to the model (in the context of MLaaS), you can get predictions which might disclose information about the training dataset. In particular you don't have any protection against membership attacks, a common attack on machine learning services where the adversary wants to determine if a specific item was used in the dataset. Besides this, other attacks such as unintended memorization processes (models learning specific feature about a data item), model inversion or extraction are still possible.\n",
    "\n",
    "One general solution which is effective for many of the threats mentioned above is to add Differential Privacy. It can be nicely combined with Secure Multi-Party Computation and can provide very interesting security guarantees. We're currently working on several implementations and hope to propose an example that combines both shortly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "As you have seen, training a model using SMPC is not complicated from a code point of view, even we use rather complex objects under the hood. With this in mind, you should now analyse your use-cases to see when encrypted computation is needed either for training or for evaluation. If encrypted computation is much slower in general, it can also be used carefully so as to reduce the overall computation overhead.\n",
    "\n",
    "If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways! \n",
    "\n",
    "### Star PySyft on GitHub\n",
    "\n",
    "The easiest way to help our community is just by starring the repositories! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Pick our tutorials on GitHub!\n",
    "\n",
    "We made really nice tutorials to get a better understanding of what Federated and Privacy-Preserving Learning should look like and how we are building the bricks for this to happen.\n",
    "\n",
    "- [Checkout the PySyft tutorials](https://github.com/OpenMined/PySyft/tree/master/examples/tutorials)\n",
    "\n",
    "\n",
    "### Join our Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! \n",
    "\n",
    "- [Join slack.openmined.org](http://slack.openmined.org)\n",
    "\n",
    "### Join a Code Project!\n",
    "\n",
    "The best way to contribute to our community is to become a code contributor! If you want to start \"one off\" mini-projects, you can go to PySyft GitHub Issues page and search for issues marked `Good First Issue`.\n",
    "\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "- [Donate through OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# speed without encyption locally\n",
    "model = Net()\n",
    "print(model)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)) #mean and std dev on dataset but how do you know if it's secret shared?\n",
    "    ])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True, transform=transformation),\n",
    "        #batch_size=args.batch_size\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        log_ps = model(images)\n",
    "        loss = ((log_ps - labels)**2).sum()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(train_loader)}\")\n",
    "        \n",
    "        \n",
    "        #test(args, model, private_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
